{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lake Levels ETL\n",
    "## Setting up db tables\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import Column, Date, Integer, String, Float, Table\n",
    "\n",
    "# import schema from python file\n",
    "from schema_lake_levels import Base\n",
    "from schema_lake_levels import Lake_names, Lake_levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tables from schema file in SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sqlite file if not exist, establish connection, create tables from schema (using 'Base')\n",
    "database_path = \"resources/lake-levels-data.sqlite\"\n",
    "engine = create_engine(f\"sqlite:///{database_path}\")\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entering tables into SQLite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lake names, ids --> reformat, enter into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAKE_NAME</th>\n",
       "      <th>LAKE_ID</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiawatha</td>\n",
       "      <td>27001800</td>\n",
       "      <td>44.921034</td>\n",
       "      <td>-93.236141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mother</td>\n",
       "      <td>27002300</td>\n",
       "      <td>44.893298</td>\n",
       "      <td>-93.241013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nokomis</td>\n",
       "      <td>27001900</td>\n",
       "      <td>44.908634</td>\n",
       "      <td>-93.242187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Taft</td>\n",
       "      <td>27068300</td>\n",
       "      <td>44.892951</td>\n",
       "      <td>-93.249752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Legion</td>\n",
       "      <td>27002400</td>\n",
       "      <td>44.885760</td>\n",
       "      <td>-93.262240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LAKE_NAME   LAKE_ID   latitude  longitude\n",
       "0  Hiawatha  27001800  44.921034 -93.236141\n",
       "1    Mother  27002300  44.893298 -93.241013\n",
       "2   Nokomis  27001900  44.908634 -93.242187\n",
       "3      Taft  27068300  44.892951 -93.249752\n",
       "4    Legion  27002400  44.885760 -93.262240"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in csv file\n",
    "lake_id_df = pd.read_csv(\"data/water-level/lakes/MCWD_Lake_ID.csv\")\n",
    "\n",
    "lake_id_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27001800</th>\n",
       "      <td>Hiawatha</td>\n",
       "      <td>44.921034</td>\n",
       "      <td>-93.236141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27002300</th>\n",
       "      <td>Mother</td>\n",
       "      <td>44.893298</td>\n",
       "      <td>-93.241013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27001900</th>\n",
       "      <td>Nokomis</td>\n",
       "      <td>44.908634</td>\n",
       "      <td>-93.242187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27068300</th>\n",
       "      <td>Taft</td>\n",
       "      <td>44.892951</td>\n",
       "      <td>-93.249752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27002400</th>\n",
       "      <td>Legion</td>\n",
       "      <td>44.885760</td>\n",
       "      <td>-93.262240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name        lat        lng\n",
       "id                                      \n",
       "27001800  Hiawatha  44.921034 -93.236141\n",
       "27002300    Mother  44.893298 -93.241013\n",
       "27001900   Nokomis  44.908634 -93.242187\n",
       "27068300      Taft  44.892951 -93.249752\n",
       "27002400    Legion  44.885760 -93.262240"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make col names lowercase\n",
    "lake_id_df.columns = ['name', 'id', 'lat', 'lng']\n",
    "\n",
    "# drop duplicate ids\n",
    "lake_id_df.drop_duplicates(subset='id', inplace=True)\n",
    "\n",
    "# set 'lake_id' as index\n",
    "lake_id_df.set_index('id', inplace=True)\n",
    "\n",
    "# preview\n",
    "lake_id_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values inserted into: 'lake_names'\n"
     ]
    }
   ],
   "source": [
    "# export lake_id_df as SQL table 'lake_names'\n",
    "lake_id_df.to_sql('lake_names', con=engine, if_exists='replace', index=True)\n",
    "print(\"Values inserted into: 'lake_names'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert all lake data for a given lake id into dict format\n",
    "def lake_to_dict(lake_id):\n",
    "\n",
    "    # grab all measurements for lake\n",
    "    elevations = list(test.loc[test.id == lake_id].elevation)\n",
    "    read_dates = list(test.loc[test.id == lake_id].read_date)\n",
    "    datum_adjs = list(test.loc[test.id == lake_id].datum_adj)\n",
    "    \n",
    "    measurements = list(zip(elevations, read_dates, datum_adjs))\n",
    "\n",
    "    measurement_keys = ['elevation', 'read_date', 'datum_adj']\n",
    "    \n",
    "    # make measurements json format\n",
    "    measurements_json = []\n",
    "    for i in range(len(aslist)):\n",
    "        measurement_dict = dict(zip(measurement_keys, aslist[i]))\n",
    "        measurements_json.append(measurement_dict)\n",
    "\n",
    "    # create lake_dict using measurements_json\n",
    "    lake_dict = {\n",
    "        'lake':\n",
    "            {\n",
    "                'name': lake_id_df['name'][lake_id],\n",
    "                'id': lake_id,\n",
    "                'location': {\n",
    "                    'lat': lake_id_df['lat'][lake_id],\n",
    "                    'lng': lake_id_df['lng'][lake_id]\n",
    "                },\n",
    "                'measurements': measurements_json\n",
    "            }\n",
    "    }\n",
    "    \n",
    "    return lake_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape lake level data for all lakes in watershed, reformat and enter into SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base url for scraping lake-level data\n",
    "base_url = \"https://files.dnr.state.mn.us/cgi-bin/lk_levels_dump.pl?format=csv&id=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for lake 1 of 141.......\n",
      "Lake id: 27001800.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 2 of 141.......\n",
      "Lake id: 27002300.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 3 of 141.......\n",
      "Lake id: 27001900.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 4 of 141.......\n",
      "Lake id: 27068300.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 5 of 141.......\n",
      "Lake id: 27002400.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 6 of 141.......\n",
      "Lake id: 27002200.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 7 of 141.......\n",
      "Lake id: 27068400.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 8 of 141.......\n",
      "Lake id: 27068500.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 9 of 141.......\n",
      "Lake id: 27001600.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 10 of 141.......\n",
      "Lake id: 27001700.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 11 of 141.......\n",
      "Lake id: 27004000.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 12 of 141.......\n",
      "Lake id: 27003100.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 13 of 141.......\n",
      "Lake id: 27003900.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 14 of 141.......\n",
      "Lake id: 27003800.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 15 of 141.......\n",
      "Lake id: 27067500.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 16 of 141.......\n",
      "Lake id: 27001500.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 17 of 141.......\n",
      "Lake id: 27065600.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 18 of 141.......\n",
      "Lake id: 27066400.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 19 of 141.......\n",
      "Lake id: 27004100.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 20 of 141.......\n",
      "Lake id: 27067000.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 21 of 141.......\n",
      "Lake id: 27066900.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 22 of 141.......\n",
      "Lake id: 27005400.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 23 of 141.......\n",
      "Lake id: 27066100.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 24 of 141.......\n",
      "Lake id: 27071000.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 25 of 141.......\n",
      "Lake id: 27005100.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 26 of 141.......\n",
      "Lake id: 27077900.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 27 of 141.......\n",
      "Lake id: 27071400.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 28 of 141.......\n",
      "Lake id: 27005300.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 29 of 141.......\n",
      "Lake id: 27005200.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 30 of 141.......\n",
      "Lake id: 27071300.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 31 of 141.......\n",
      "Lake id: 27008400.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 32 of 141.......\n",
      "Lake id: 27008200.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 33 of 141.......\n",
      "Lake id: 27077100.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 34 of 141.......\n",
      "Lake id: 27075100.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 35 of 141.......\n",
      "Lake id: 27075000.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 36 of 141.......\n",
      "Lake id: 27074700.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 37 of 141.......\n",
      "Lake id: 27073900.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 38 of 141.......\n",
      "Lake id: 27013300.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 39 of 141.......\n",
      "Lake id: 27074600.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 40 of 141.......\n",
      "Lake id: 27068701.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 41 of 141.......\n",
      "Lake id: 27013301.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 42 of 141.......\n",
      "Lake id: 27008500.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 43 of 141.......\n",
      "Lake id: 99001038.........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 44 of 141.......\n",
      "Lake id: 27009500.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 45 of 141.......\n",
      "Lake id: 27010800.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 46 of 141.......\n",
      "Lake id: 27046800.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 47 of 141.......\n",
      "Lake id: 27008600.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 48 of 141.......\n",
      "Lake id: 27082200.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 49 of 141.......\n",
      "Lake id: 27082400.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 50 of 141.......\n",
      "Lake id: 27013302.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 51 of 141.......\n",
      "Lake id: 27010900.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 52 of 141.......\n",
      "Lake id: 27008700.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 53 of 141.......\n",
      "Lake id: 27087000.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 54 of 141.......\n",
      "Lake id: 27013400.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 55 of 141.......\n",
      "Lake id: 27013303.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 56 of 141.......\n",
      "Lake id: 27087600.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 57 of 141.......\n",
      "Lake id: 27015800.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 58 of 141.......\n",
      "Lake id: 27015900.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 59 of 141.......\n",
      "Lake id: 27013800.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 60 of 141.......\n",
      "Lake id: 27087700.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 61 of 141.......\n",
      "Lake id: 27014200.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 62 of 141.......\n",
      "Lake id: 27013304.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 63 of 141.......\n",
      "Lake id: 27016000.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 64 of 141.......\n",
      "Lake id: 27014100.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 65 of 141.......\n",
      "Lake id: 27014400.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 66 of 141.......\n",
      "Lake id: 27089600.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 67 of 141.......\n",
      "Lake id: 27015700.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 68 of 141.......\n",
      "Lake id: 27089800.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 69 of 141.......\n",
      "Lake id: 27016100.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 70 of 141.......\n",
      "Lake id: 27014300.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 71 of 141.......\n",
      "Lake id: 27014000.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 72 of 141.......\n",
      "Lake id: 27090000.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 73 of 141.......\n",
      "Lake id: 27015600.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 74 of 141.......\n",
      "Lake id: 27015500.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 75 of 141.......\n",
      "Lake id: 27090800.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 76 of 141.......\n",
      "Lake id: 27015000.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 77 of 141.......\n",
      "Lake id: 27015100.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 78 of 141.......\n",
      "Lake id: 27013310.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 79 of 141.......\n",
      "Lake id: 27091200.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 80 of 141.......\n",
      "Lake id: 27013305.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 81 of 141.......\n",
      "Lake id: 27013311.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 82 of 141.......\n",
      "Lake id: 27016200.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 83 of 141.......\n",
      "Lake id: 10000900.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 84 of 141.......\n",
      "Lake id: 99001005.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 85 of 141.......\n",
      "Lake id: 27013312.........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 86 of 141.......\n",
      "Lake id: 27051800.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 87 of 141.......\n",
      "Lake id: 27013313.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 88 of 141.......\n",
      "Lake id: 27052200.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 89 of 141.......\n",
      "Lake id: 10020600.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 90 of 141.......\n",
      "Lake id: 10001100.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 91 of 141.......\n",
      "Lake id: 27015400.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 92 of 141.......\n",
      "Lake id: 10001500.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 93 of 141.......\n",
      "Lake id: 27013900.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 94 of 141.......\n",
      "Lake id: 10001000.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 95 of 141.......\n",
      "Lake id: 27013306.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 96 of 141.......\n",
      "Lake id: 27096500.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 97 of 141.......\n",
      "Lake id: 27094500.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 98 of 141.......\n",
      "Lake id: 27040800.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 99 of 141.......\n",
      "Lake id: 99000999.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 100 of 141.......\n",
      "Lake id: 10001800.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 101 of 141.......\n",
      "Lake id: 27094800.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 102 of 141.......\n",
      "Lake id: 27013315.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 103 of 141.......\n",
      "Lake id: 27013314.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 104 of 141.......\n",
      "Lake id: 27094700.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 105 of 141.......\n",
      "Lake id: 10004500.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 106 of 141.......\n",
      "Lake id: 10004100.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 107 of 141.......\n",
      "Lake id: 10020001.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 108 of 141.......\n",
      "Lake id: 10004600.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 109 of 141.......\n",
      "Lake id: 10020002.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 110 of 141.......\n",
      "Lake id: 10004700.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 111 of 141.......\n",
      "Lake id: 10004800.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 112 of 141.......\n",
      "Lake id: 27018200.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 113 of 141.......\n",
      "Lake id: 10005600.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 114 of 141.......\n",
      "Lake id: 10005400.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 115 of 141.......\n",
      "Lake id: 10004400.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 116 of 141.......\n",
      "Lake id: 27109600.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 117 of 141.......\n",
      "Lake id: 27018100.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 118 of 141.......\n",
      "Lake id: 10013400.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 119 of 141.......\n",
      "Lake id: 27095200.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 120 of 141.......\n",
      "Lake id: 10013500.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 121 of 141.......\n",
      "Lake id: 10005000.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 122 of 141.......\n",
      "Lake id: 27013309.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 123 of 141.......\n",
      "Lake id: 27018500.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 124 of 141.......\n",
      "Lake id: 10004401.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 125 of 141.......\n",
      "Lake id: 10005300.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 126 of 141.......\n",
      "Lake id: 10013800.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 127 of 141.......\n",
      "Lake id: 10019100.........\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 128 of 141.......\n",
      "Lake id: 27018300.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 129 of 141.......\n",
      "Lake id: 10004900.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 130 of 141.......\n",
      "Lake id: 10013900.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 131 of 141.......\n",
      "Lake id: 27095800.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 132 of 141.......\n",
      "Lake id: 27093900.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 133 of 141.......\n",
      "Lake id: 27095700.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 134 of 141.......\n",
      "Lake id: 10014000.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 135 of 141.......\n",
      "Lake id: 10004300.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 136 of 141.......\n",
      "Lake id: 10014100.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 137 of 141.......\n",
      "Lake id: 10005100.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 138 of 141.......\n",
      "Lake id: 10004200.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 139 of 141.......\n",
      "Lake id: 10019000.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 140 of 141.......\n",
      "Lake id: 27018600.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Getting data for lake 141 of 141.......\n",
      "Lake id: 10014300.........\n",
      "..............Values successfully inserted into 'lake_levels'\n",
      "------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# variable to track progress of loop\n",
    "lake_count = 0\n",
    "\n",
    "# store ids for lakes that failed and succeeded to be inserted\n",
    "failed = []\n",
    "successful = []\n",
    "\n",
    "df_list = []\n",
    "\n",
    "# loop through index of lake_id_df (lake ids are the index)\n",
    "for lake_id in lake_id_df.index:\n",
    "    \n",
    "    lake_count += 1\n",
    "    print(f\"Getting data for lake {lake_count} of {len(lake_id_df.index)}.......\")\n",
    "    print(f\"Lake id: {lake_id}.........\")\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # read data from url into df\n",
    "        df = pd.read_csv(f\"{base_url}{lake_id}\")\n",
    "\n",
    "        # change column names to lowercase\n",
    "        df.columns = map(str.lower, df.columns)\n",
    "\n",
    "        # rename 'chr_id' to 'id'\n",
    "        df.rename(columns={\"chr_id\": \"id\"}, inplace=True)\n",
    "\n",
    "        # drop duplicate date entries\n",
    "        df.drop_duplicates(subset='read_date', inplace=True)\n",
    "        \n",
    "        df_list.append(df.copy())\n",
    "        \n",
    "        # set multi-index for multiple primary keys\n",
    "        df.set_index(['id', 'read_date'], inplace=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # insert df into sql table 'lake_levels'\n",
    "        df.to_sql('lake_levels', con=engine, if_exists='append', index=True, index_label=['id', 'read_date'])\n",
    "        print(\"..............Values successfully inserted into 'lake_levels'\")\n",
    "        print(\"------------------------------------------------------------------\\n\\n\")\n",
    "        successful.append(lake_id)\n",
    "    except:\n",
    "        print(\".......................Process failed\")\n",
    "        print(\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\\n\\n\")\n",
    "        failed.append(lake_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed additions: 0\n",
      "----------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print failed lake additions\n",
    "print(f\"Failed additions: {len(failed)}\")\n",
    "print(\"----------------------------------------------\\n\")\n",
    "for id in failed:\n",
    "    print(id, lake_id_df.name[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful additions: 141\n",
      "----------------------------------------------\n",
      "\n",
      "27001800 Hiawatha\n",
      "27002300 Mother\n",
      "27001900 Nokomis\n",
      "27068300 Taft\n",
      "27002400 Legion\n",
      "27002200 Diamond\n",
      "27068400 Milner Pond\n",
      "27068500 Norby's Pond\n",
      "27001600 Harriet\n",
      "27001700 Cemetery\n",
      "27004000 Lake of the Isles\n",
      "27003100 Calhoun\n",
      "27003900 Cedar\n",
      "27003800 Brownie\n",
      "27067500 Pamela Pond\n",
      "27001500 Bass\n",
      "27065600 Twin\n",
      "27066400 Wolfe Park\n",
      "27004100 Edina Mill Pond\n",
      "27067000 Harvey\n",
      "27066900 Melody\n",
      "27005400 Meadowbrook\n",
      "27066100 South Oak\n",
      "27071000 Lamplighter\n",
      "27005100 Victoria\n",
      "27077900 Unnamed\n",
      "27071400 Westling\n",
      "27005300 Unnamed (Cobblecrest)\n",
      "27005200 Hannan\n",
      "27071300 Unnamed (Cedar Manor)\n",
      "27008400 Minnehaha Marsh\n",
      "27008200 Windsor\n",
      "27077100 Unnamed\n",
      "27075100 Unnamed\n",
      "27075000 Unnamed\n",
      "27074700 Unnamed\n",
      "27073900 Unnamed\n",
      "27013300 Gray's Bay Outlet\n",
      "27074600 Unnamed\n",
      "27068701 Unnamed (East)\n",
      "27013301 Grays Bay\n",
      "27008500 Libbs\n",
      "99001038 Unnamed\n",
      "27009500 Gleason\n",
      "27010800 Snyder\n",
      "27046800 Unnamed\n",
      "27008600 Shaver\n",
      "27082200 Unnamed\n",
      "27082400 Unnamed\n",
      "27013302 Wayzata Bay\n",
      "27010900 Hadley\n",
      "27008700 Marion\n",
      "27087000 Louise\n",
      "27013400 Mooney\n",
      "27013303 Carsons Bay\n",
      "27087600 Hooper\n",
      "27015800 Holy Name\n",
      "27015900 Lydiard\n",
      "27013800 Peavey Lake\n",
      "27087700 Unnamed\n",
      "27014200 William\n",
      "27013304 St. Albans Bay\n",
      "27016000 Long\n",
      "27014100 Tanager Lake\n",
      "27014400 Galpin\n",
      "27089600 Unnamed (Mud)\n",
      "27015700 Wolsfeld\n",
      "27089800 Unnamed\n",
      "27016100 Dickey's\n",
      "27014300 Mary\n",
      "27014000 French Marsh\n",
      "27090000 Unnamed\n",
      "27015600 Thies\n",
      "27015500 Krieg\n",
      "27090800 Unnamed\n",
      "27015000 Marsh\n",
      "27015100 School\n",
      "27013310 Crystal Bay\n",
      "27091200 Unnamed\n",
      "27013305 Carman Bay\n",
      "27013311 Maxwell Bay\n",
      "27016200 Classen\n",
      "10000900 Minnewashta\n",
      "99001005 Unnamed\n",
      "27013312 Stubbs Bay\n",
      "27051800 Academy Marsh\n",
      "27013313 North Arm\n",
      "27052200 Unnamed\n",
      "10020600 Unnamed\n",
      "10001100 St. Joe\n",
      "27015400 Katrina\n",
      "10001500 Virginia\n",
      "27013900 Forest Lake\n",
      "10001000 Tamarack\n",
      "27013306 Black Lake\n",
      "27096500 Unnamed\n",
      "27094500 Unnamed\n",
      "27040800 Unnamed\n",
      "99000999 Unnamed\n",
      "10001800 Schutz\n",
      "27094800 Unnamed\n",
      "27013315 Jennings Bay\n",
      "27013314 Harrisons Bay\n",
      "27094700 Unnamed\n",
      "10004500 Steiger\n",
      "10004100 Zumbra\n",
      "10020001 Unnamed (north portion)\n",
      "10004600 Church\n",
      "10020002 Unnamed (south portion)\n",
      "10004700 Kelser's Pond\n",
      "10004800 Wassermann\n",
      "27018200 Langdon\n",
      "10005600 Stone\n",
      "10005400 Marsh\n",
      "10004400 East Auburn\n",
      "27109600 Unnamed\n",
      "27018100 Dutch\n",
      "10013400 Sunny\n",
      "27095200 Unnamed\n",
      "10013500 Unnamed\n",
      "10005000 Carl Krey\n",
      "27013309 Halsted Bay\n",
      "27018500 Saunders\n",
      "10004401 West Auburn\n",
      "10005300 Piersons\n",
      "10013800 Unnamed\n",
      "10019100 Unnamed\n",
      "27018300 Unnamed (Black)\n",
      "10004900 Unnamed (Auburn Marsh)\n",
      "10013900 Unnamed\n",
      "27095800 Unnamed\n",
      "27093900 Unnamed\n",
      "27095700 Unnamed\n",
      "10014000 Unnamed\n",
      "10004300 Lundsten South Bay\n",
      "10014100 Unnamed\n",
      "10005100 Turbid\n",
      "10004200 Parley\n",
      "10019000 Unnamed\n",
      "27018600 Mud\n",
      "10014300 Unnamed\n"
     ]
    }
   ],
   "source": [
    "# print successful additions\n",
    "print(f\"Successful additions: {len(successful)}\")\n",
    "print(\"----------------------------------------------\\n\")\n",
    "for id in successful:\n",
    "    print(id, lake_id_df.name[id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate all df's created into big df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_levels_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>elevation</th>\n",
       "      <th>read_date</th>\n",
       "      <th>datum_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27001800</td>\n",
       "      <td>811.40</td>\n",
       "      <td>1926-04-15</td>\n",
       "      <td>NGVD 29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27001800</td>\n",
       "      <td>815.35</td>\n",
       "      <td>1926-08-05</td>\n",
       "      <td>NGVD 29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27001800</td>\n",
       "      <td>812.72</td>\n",
       "      <td>1927-03-29</td>\n",
       "      <td>NGVD 29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27001800</td>\n",
       "      <td>813.04</td>\n",
       "      <td>1927-11-30</td>\n",
       "      <td>NGVD 29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27001800</td>\n",
       "      <td>814.50</td>\n",
       "      <td>1928-04-12</td>\n",
       "      <td>NGVD 29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  elevation   read_date datum_adj\n",
       "0  27001800     811.40  1926-04-15   NGVD 29\n",
       "1  27001800     815.35  1926-08-05   NGVD 29\n",
       "2  27001800     812.72  1927-03-29   NGVD 29\n",
       "3  27001800     813.04  1927-11-30   NGVD 29\n",
       "4  27001800     814.50  1928-04-12   NGVD 29"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake_levels_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
